Taiyo.ai Data Engineer Task Summary

Hello, I’m G. Sindhu Vaishnavi applying for the role of Data Engineer (Web Scraper).
I’m a complete novice to this process and even though I tried my best to complete the task with a successful resolution, I could only write the program partially.
I’m uploading the program file and summary to the Google Drive and also pushing this code for your evaluation.
I have done some research and web surfing about Web Scraping and I’m describing the theoretical aspects of what I understood regarding Web Scraping below in my own words:

Introduction:
Web Scraping is the process of extracting Data from a Web Page.
Some Web Pages may or may not allow Web Scraping. So, checking with owner of the Website or obtaining a consent is necessary to determine if it is legal or illegal.
The thorough idea of what data is to be scraped from the Web Page is the essential task.
Manually, the data from a web page – be it the whole web page or a portion of the raw data which is not in a sorted manner can be scraped by copying the web page.
However, it takes a lot of time and effort. For extracting data from multiple web pages, it is a tedious task.
With the help of Python, we can do this the whole task of extracting the data by writing a Python code into a function which in turn is placed into a class. When this class is executed, the whole process gets completed.
Then, the scraped unsorted/ raw data is to be neatly cleaned into sorted data and can be stored in a CSV format file.
So, scraping the data is Part One and converting it to a suitable sorted format is Part Two.

Process of Web Scraping:
Choosing a website and having the url of the website.
Inspecting the website by right clicking on the website and select the ‘Inspect’ option which shows the HTML Code with all the elements of the web page.
Installing the required libraries which perform their specific tasks such as BeautifulSoup, MechanicalSoup, Selenium, Scrapy, requests, pandas etc.
Writing the Python code which performs the task of sending HTTP GET request to the website, parsing the HTML Code of the website using BeatifulSoup, extracting required data, storing it in pandas Dataframe and finally receiving the output in CSV file format which can be verified for the desired result.

Thanking you for this opportunity which helped me to learn and gain real time work Experience.

